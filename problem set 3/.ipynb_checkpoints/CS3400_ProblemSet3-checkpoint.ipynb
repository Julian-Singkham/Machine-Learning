{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Name: \n",
    "\n",
    "CS 3400\n",
    "\n",
    "Problem Set 3\n",
    "\n",
    "---\n",
    "\n",
    "*NOTE: this file is adapted from the original pdf form. You may complete the following entirely in a Jupyter notebook. Ensure that the notebook has your name on it. Save the notebook as a PDF and submit the PDF through Canvas.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Standardization\n",
    "Many machine learning algorithms are sensitive to the centering and scaling of features. Let’s walk\n",
    "through what this means. To “center” data, we shift the data so that the mean is $0$. We do this\n",
    "by subtracting the mean $\\bar{x}$ value from every data point.\n",
    "$$z=x-\\bar{x}$$\n",
    "To “scale” data, we want to “squish” the data so that the standard deviation is $1$. We do this by\n",
    "dividing every data point by the standard deviation $\\sigma$.\n",
    "$$z=\\frac{x}{\\sigma}$$\n",
    "We often combine these into a single equation:\n",
    "$$z=\\frac{x-\\bar{x}}{\\sigma}$$\n",
    "A few notes on best practices: Centering and scaling is done independently for every column in the\n",
    "feature matrix. When using training and testing sets, we calculate $\\hat{x}$ and $\\sigma$ from the training set\n",
    "and use both to center and scale the training and testing sets.\n",
    "\n",
    "(a) Load the data from the file peaks lfc.csv using Pandas. (It only contains one column.)  \n",
    "(b) Plot a histogram of the data. Hint: use Seaborn’s distplot function.  \n",
    "(c) Center the data. Plot the histogram. What’s different? Hint: Use Numpy’s mean function.  \n",
    "(d) Scale the data. Plot the histogram. What’s different? Hint: Use Numpy’s std function.  \n",
    "(e) Both center and scale the data. Plot the histogram. What’s different?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Observation distances\n",
    "Explore how distance from the decision boundary is related to the output of our linear models.\n",
    "1. Load in the IRIS dataset and put the first two features into a feature matrix. Plot these observations\n",
    "2. Plot the decision boundry from lab 3 on the figure.\n",
    "  1. $y=0.75x-0.9$\n",
    "3. Find the projections from each observation to the line and plot a line segment for each observation\n",
    "  1. We are finding the orthagonal projection of a point (observation) to the line (model)\n",
    "  2. Note that we are looking for line segments that are orthagonal to the model\n",
    "    1. The model is in the form of $y=m_{model}x+b$\n",
    "    2. We want to solve for the orthagonal slope $m_{orthagonal}$\n",
    "    3. $m_{model}m_{orthagonal}=-1\\rightarrow m_{orthagonal}=-\\frac{4}{3}$\n",
    "    4. This gives us a \"line template\" of $y=-\\frac{4}{3}x+b$, and now we have to solve for $b$ given our point (observation)\n",
    "    5. Given the first point in the dataset - $Obs_1=(5.1, 3.5)$, we can solve $3.5=-\\frac{4}{3}(5.1)+b\\rightarrow b=10.3$\n",
    "    6. Now we have two equations and two unknowns\n",
    "        1. $y=\\frac{3}{4}x-0.9$\n",
    "        2. $y=-\\frac{4}{3}x+10.3$\n",
    "    7. We can put these in a standard form:\n",
    "        1. $\\frac{3}{4}x-y=0.9$\n",
    "        2. $-\\frac{4}{3}x-y=-10.3$\n",
    "    8. In the standard form we can use linear algebra to solve for the system of equations:\n",
    "        1. $\\begin{bmatrix}\n",
    "            \\frac{3}{4} & -1 \\\\\n",
    "            -\\frac{3}{4} & -1\n",
    "           \\end{bmatrix}\n",
    "           \\begin{bmatrix}\n",
    "            x \\\\\n",
    "            y\n",
    "           \\end{bmatrix}\n",
    "           =\n",
    "           \\begin{bmatrix}\n",
    "            0.9 \\\\\n",
    "            -10.3\n",
    "           \\end{bmatrix}$\n",
    "        2. $\\begin{bmatrix}\n",
    "            x \\\\\n",
    "            y\n",
    "           \\end{bmatrix}\n",
    "           =\n",
    "           \\begin{bmatrix}\n",
    "            \\frac{3}{4} & -1 \\\\\n",
    "            -\\frac{3}{4} & -1\n",
    "           \\end{bmatrix}^{-1}\n",
    "           \\begin{bmatrix}\n",
    "            0.9 \\\\\n",
    "            -10.3\n",
    "           \\end{bmatrix}$\n",
    "        3. Where $(x, y)$ is the projection of our point (observation) onto the line (model)\n",
    "    9. you now have two points, solve for the distance between the two points\n",
    "        1. $||a-b||\\rightarrow 0.46$\n",
    "    10. Add a vector to your figure that connects the point on the model to the observation in space, color it according to the distance.\n",
    "    11. Do this for all observations in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Practice KNN by hand.\n",
    "Note that this problem needs to be done on paper, not in a notebook.  \n",
    "\n",
    "---\n",
    "\n",
    "NOTE: Do this problem on paper then scan it and include it as a figure as part of this problem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) The bias-variance tradeoff\n",
    "A model’s error can be decomposed into variance, bias and irreducible error:\n",
    "\n",
    "- Bias refers to the error that is introduced due to wrong assumptions such as approximating a complicated pattern in data with a simple model. A high-bias model is a model that fails to capture the structure in data and results in underfitting the training data. High bias or underfitting is usually caused by a model that is too simple or when there is a few features.\n",
    "- Variance refers to the amount by which the model would change if we used a different training data set. A high-variance model is a model that does not generalize well to predict new data but performs well on training data, which is also know as overfitting. High variance or overfitting is usually caused by a model that is too complex for the data.\n",
    "- Irreducible error refers to the noise that exists in the data itself.\n",
    "\n",
    "In general, there is a tradeoff between bias and variance. As the model’s complexity increases (for example going from a simple linear model to a polynomial model with a higher degree), its bias will typically decrease but its variance will increase. As the model’s complexity decreases, its variance will decrease but its bias will increase.\n",
    "\n",
    "\n",
    "When a model does not perform well on the training set, we know that the model underfits the training set. When a model performs very well on the training set, but fails to show similar performance on the test set, we conclude that the model overfits the training set (hence the importance of splitting data into training and test sets).\n",
    "\n",
    "\n",
    "In this exercise, you will visualize the bias-variance tradeoff of a KNN model. The complexity of a KNN model can be varied by changing k (the number of nearest neighbors).\n",
    "\n",
    "1. How do you expect the complexity of a KNN classifier will change if $k$ increases? In other words, as we increase $k$, will the decision boundary become simpler and smoother or will it have more angles and curves?\n",
    "2. Load diabetes.csv and extract the feature matrix $X$ and the label vector $y$ . The data consists of diagnostic measurements for some female patients and shows whether they have diabetes or not, as indicated by the last column labeled as outcome. (The data was extracted from here).\n",
    "3. Use the scikit-learn implementation of KNN (KNeighborsClassifier‘) to instantiate a KNN classifier. For now, keep the default value for the number of neighbors.\n",
    "4. You will now evaluate the model using cross validation. Use the method cross validate provided by scikit-learn to evaluate KNN. This method splits the data into 5 folds and returns the training scores and testing scores for each fold. Make sure to set the argument return train score to True. Find the average of the $5$ training scores and the average of the $5$ testing scores.\n",
    "5. KNeighborsClassifier uses $k=5$ (number of neighbors) by default. Repeat what you did in the previous part by varying $k$ from $1$ to $50$. For each value of $k$, find the average accuracy score and the average testing score. On a same figure, plot two lines: one showing how thetraining accuracy changes with $k$ and another line showing how the testing accuracy changes with $k$.\n",
    "6. Can you spot where the model has high variance (overfitting) and where it has low variance?\n",
    "7. KNN can be also used for regression. Repeat the previous steps using the scikit-learn implementation of KNN regressor (KNeighborsRegressor). For this part, load the boston dataset that is provided by scikit-learn (load boston) and use the mean squared error (mean squared error) as evaluation metric: you will need to specify the scoring argument in cross validate as scoring = make scorer(mean squared error). Vary $k$ from $1$ to $400$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) The curse of dimensionality\n",
    "---\n",
    "\n",
    "Note: this problem has some pictures which were unable to be adapted to the notebook from the original PDF format.\n",
    "\n",
    "---\n",
    "\n",
    "This exercise was adapted from the book “Introduction to Statistical Learning” (exercise 4 in chapter 4). \n",
    "\n",
    "KNN tends to perform poorly as the number of features increases. This is due to a phenomenon known as the curse of dimensionality, which we will explore in this exercise.\n",
    "\n",
    "---\n",
    "\n",
    "1. Suppose we have a set of observations that consist of one feature; those obervations cover uniformly the interval from $0$ to $1$ (the black line shown in (a)). Suppose that we wish to predict the response for a new observation (the black dot shown in (a)); this new observation is centered in a sub-interval of length $\\lambda$ observations. To make the prediction for this new data point, we want to only use the observations that lie in this sub-interval (the blue line shown in (a)). On average, what fraction of the available observations we will use to make this prediction?\n",
    "2. Suppose we have a set of observations that consist of two features; those obervations cover uniformly the unit square (the black square shown in (b)). Suppose that we wish to predict the response for a new observation (the black dot shown in (b)); this new observation is centered in a smaller square with $\\lambda$ as the side length. To make the prediction for this new data point, we want to only use the observations that lie in this small square (the blue square shown in (b)). On average, what fraction of the available observations we will use to make this prediction?\n",
    "3. Repeat the same question for when the data has 3 features (as shown in (c)). Can you generalize your answer for any number of features $p$?\n",
    "4. Using the general form from subpart 3 and assuming that $\\lambda = 0.1$ (representing the fraction of needed observations), how does the fraction of the available observations used in prediction change with $p$? You can show a plot or explain your answer. Can you argue that a disadvantage of KNN is that when $p$ is large, there are few observations that are close to the new datapoint? Optional - you can think about the fraction of observations as $\\frac{k}{N}$, where $k$ is the number of nearest neighbors and $N$ is the number of observations. How many observations ($N$ expressed in terms of $p$) do we need for $k = 10$ and $\\lambda = 0.1$?\n",
    "5. Assume that you need inside the hypercube $10%$ of the available observations. (Note: a hypercube is a generalization of a cube; when $p=1$ it is a line, when $p=2$ it is a square, when $p=3$ it is a cube). What is the length of each side of the hypercube? How does the length change as $p$ increases? Again you can show a plot or explain your answer. Can you argue that when $p$ is large, what KNN assumes as a near neighbor to a data point, might not be actually similar to this data point?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
